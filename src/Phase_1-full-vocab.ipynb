{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "from flair.embeddings import WordEmbeddings, TransformerWordEmbeddings\n",
    "from flair.data import Sentence\n",
    "import networkx as nx\n",
    "from pytorch_pretrained_bert import BertTokenizer\n",
    "import torch\n",
    "from networkx.algorithms import approximation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "from sklearn.metrics.pairwise import cosine_similarity,cosine_distances\n",
    "from tqdm.notebook import tqdm\n",
    "import pickle\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_thresh = 0.98\n",
    "visual_thresh = 0.9\n",
    "lancaster_thresh = 0.98\n",
    "free_asoc_threshold =  0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recreate the Multiplex Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_degree_connectivity(graph_name):\n",
    "    num_edges = 0\n",
    "    for node in graph_name.nodes():\n",
    "        num_edges += len(graph_name.edges(node))\n",
    "\n",
    "    return num_edges/graph_name.number_of_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perc_nodes_in_lcc(graph_name):\n",
    "    largest_cc = max(nx.connected_components(graph_name), key=len)\n",
    "    lenght = len(largest_cc)\n",
    "    return lenght/graph_name.number_of_nodes()\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_shortest_path_lcc(graph_name):\n",
    "    S = [graph_name.subgraph(c).copy() for c in nx.connected_components(graph_name)]\n",
    "    comps = [len(max(nx.connected_components(i), key=len)) for i in S]\n",
    "    index_max = max(range(len(comps)), key=comps.__getitem__)\n",
    "    return nx.average_shortest_path_length(S[index_max])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create free association layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "faw = [line.strip().split('\\t') for line in open('../data/freeassoc_full.csv')]\n",
    "words = list(set(line[0] for line in faw))\n",
    "# faw = [line for line in faw if len(line) == 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a\\tone', 'a\\tthe', 'aardvark\\tanimal', 'aardvark\\tanteater', 'abacus\\tmath']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "free_association_words =  ['\\t'.join(line[:2]) for line in faw if float(line[4]) > free_asoc_threshold]\n",
    "\n",
    "free_association_words[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up the data and store it into lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "free_association_list = []\n",
    "\n",
    "for pair in free_association_words:\n",
    "    free_association_list.append(tuple(map(str, pair.split('\\t'))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Free associations Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12217"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiplex = nx.Graph()\n",
    "multiplex.add_nodes_from(words)\n",
    "\n",
    "free_assoc = nx.Graph()\n",
    "free_assoc.add_nodes_from(words)\n",
    "len(free_assoc.nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the free association layer to the multiplex\n",
    "for pair in free_association_list:\n",
    "    multiplex.add_edge(pair[0], pair[1])\n",
    "    \n",
    "# Add the free association layer to its graph\n",
    "for pair in free_association_list:\n",
    "    free_assoc.add_edge(pair[0], pair[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12600"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(free_assoc.nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Mean degree of connectivity _k_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.9576984126984125"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_degree_connectivity(free_assoc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Mean Clustering Coefficient _CC_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12690427571331633"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx.average_clustering(free_assoc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Assortativity Coefficient _a_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.15218634277569373"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx.degree_assortativity_coefficient(free_assoc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Percentage of nodes in the Largest Connected Component _Conn._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perc_nodes_in_lcc(free_assoc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) Mean Shortest Path lenght in the Largest Connected Component _d_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean_shortest_path_lcc(free_assoc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We have added one layer to multiplex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18636"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiplex.number_of_edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(r\"free_assoc_full.pickle\", \"rb\") as input_file:\n",
    "#     free_association_list = pickle.load(input_file)\n",
    "    \n",
    "# free_association_list = {a:b for a,b in free_association_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(free_association_list, open( \"free_assoc_full.pickle\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the BERT Word Embedding Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# glove_embedding = WordEmbeddings('glove')\n",
    "embedding = TransformerWordEmbeddings('bert-base-uncased', layers='-1', layer_mean=True)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# embd_vocab  = list(glove_embedding.precomputed_word_embeddings.key_to_index.keys())\n",
    "\n",
    "# len(embd_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30522"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_vocab = list(tokenizer.vocab.keys())\n",
    "\n",
    "len(bert_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc60d562593b468ebb4c18bdb35795fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30522 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "word_emb = {}\n",
    "for word in tqdm(bert_vocab):\n",
    "    sentence = Sentence(word) # --> strip() removes the white space from beginning and end of word\n",
    "     # embed a sentence using glove.\n",
    "    embedding.embed(sentence)\n",
    "    for token in sentence:\n",
    "        word_emb[word]=token.embedding\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_emb['red'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30522"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(word_emb, open( \"word_emb_layer_full.pickle\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_emb_layer = nx.Graph()\n",
    "word_emb_layer.add_nodes_from(bert_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute distance using cosine similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fc061dca3964ee5bc72e19701f46967",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/465796242.0 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "word_emb_list = []\n",
    "emb_vocab = list(word_emb.keys())\n",
    "\n",
    "with tqdm(total=len(emb_vocab)*len(emb_vocab)/2.0) as pbar:\n",
    "    while len(emb_vocab) > 0:\n",
    "        item = emb_vocab.pop()\n",
    "        x = word_emb[item]\n",
    "\n",
    "        for word in emb_vocab:\n",
    "            y = word_emb[word]\n",
    "#             print(x.unsqueeze(0))\n",
    "            cosine_sim = torch.cosine_similarity(x.unsqueeze(0), y.unsqueeze(0))\n",
    "#             print(item, word, cosine_sim)\n",
    "            if cosine_sim > word_thresh:\n",
    "#                 print(cosine_sim, item, word)\n",
    "                word_emb_list.append((item, word))\n",
    "#                 print(len(word_emb_list))\n",
    "                word_emb_layer.add_edge(item, word)\n",
    "        pbar.update(len(emb_vocab))                   \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(word_emb_list, open( \"word_emb_list_98.pickle\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "147726"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_emb_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Mean Dregree of connectivity _k_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_degree_connectivity(word_emb_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Mean Clustering Coefficient _CC_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx.average_clustering(word_emb_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Assortativity Coefficient _a_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "max() arg is an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-bcfe978703c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdegree_assortativity_coefficient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_emb_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/networkx/algorithms/assortativity/correlation.py\u001b[0m in \u001b[0;36mdegree_assortativity_coefficient\u001b[0;34m(G, x, y, weight, nodes)\u001b[0m\n\u001b[1;32m     75\u001b[0m        \u001b[0mEdge\u001b[0m \u001b[0mdirection\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mstructure\u001b[0m \u001b[0mof\u001b[0m \u001b[0mnetworks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPNAS\u001b[0m \u001b[0;36m107\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10815\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m20\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2010\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \"\"\"\n\u001b[0;32m---> 77\u001b[0;31m     \u001b[0mM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdegree_mixing_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnumeric_ac\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/networkx/algorithms/assortativity/mixing.py\u001b[0m in \u001b[0;36mdegree_mixing_matrix\u001b[0;34m(G, x, y, weight, nodes, normalized)\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m     \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m     \u001b[0mmapping\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict_to_numpy_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: max() arg is an empty sequence"
     ]
    }
   ],
   "source": [
    "nx.degree_assortativity_coefficient(word_emb_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Percentage of nodes in the LCC _Conn._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perc_nodes_in_lcc(word_emb_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) Mean shortest path in LLC _d_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_shortest_path_lcc(word_emb_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(word_emb_layer.nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the Visual Embedding Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('../data/clip.bertvocab.embeddings.513.txt', 'r')\n",
    "lines = file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30522"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visual_vecs = {}\n",
    "for line in lines:\n",
    "    visual_vecs[line.split()[0]] = line.split()[1:]\n",
    "    \n",
    "visual_words = list(visual_vecs.keys())\n",
    "\n",
    "len(visual_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "513"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(visual_vecs['car'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(visual_vecs, open( \"word_emb_layer_full.pickle\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30522"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visual_graph = nx.Graph()\n",
    "visual_graph.add_nodes_from(visual_words)\n",
    "len(visual_graph.nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10c85885dcb04b7e85c1d01f2e2527d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/465796242.0 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visual_list = []\n",
    "\n",
    "visual_words_chop = visual_words.copy()\n",
    "\n",
    "with tqdm(total=len(visual_words_chop)*len(visual_words_chop)/2.0) as pbar:\n",
    "    while len(visual_words_chop) > 0:\n",
    "        item = visual_words_chop.pop()\n",
    "        x = np.array(visual_vecs[item])\n",
    "#         print(item, len(visual_words_chop))\n",
    "        for word in visual_words_chop:\n",
    "#             if word is not item:\n",
    "            y = np.array(visual_vecs[word])\n",
    "\n",
    "            cosine_sim = cosine_similarity(x.reshape(1,-1),y.reshape(1,-1))\n",
    "\n",
    "            if cosine_sim > visual_thresh:\n",
    "                visual_list.append((item, word))\n",
    "                visual_graph.add_edge(item, word)\n",
    "        pbar.update(len(visual_words_chop))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30522"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(visual_graph.nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Mean Degree of Connectivity _k_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_degree_connectivity(visual_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Mean Clustering Coefficient _CC_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.average_clustering(visual_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Assortativity Coefficient _a_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.degree_assortativity_coefficient(visual_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Percentage of nodes in the LCC _Conn._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perc_nodes_in_lcc(visual_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) Mean shortest length in the LCC _d_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_shortest_path_lcc(visual_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(visual_list, open( \"visual_layer_vectors_full.pickle\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(visual_graph.nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the Lancaster Embedding Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "norms = pd.read_csv('../data/lancaster_full.csv')\n",
    "cols = norms.describe().columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize all columns\n",
    "for col in cols:\n",
    "    m = norms[col].max()\n",
    "    norms[col] = norms[col] / m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "vecs = {}\n",
    "\n",
    "for i,row in norms.iterrows():\n",
    "    vecs[row.Word.lower()] =  row[cols].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vecs['red'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'a cappella',\n",
       " 'aardvark',\n",
       " 'aback',\n",
       " 'abacus',\n",
       " 'abandon',\n",
       " 'abandoned',\n",
       " 'abandonee',\n",
       " 'abandoner',\n",
       " 'abandonment']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lancaster_words = list(vecs.keys())\n",
    "\n",
    "lancaster_words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(vecs, open( \"lancaster_layer_vectors_full.pickle\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39707"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lancaster = nx.Graph()\n",
    "lancaster.add_nodes_from(lancaster_words)\n",
    "len(lancaster.nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77aded505c094796bc78188c82f9bda5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/788322924.5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lancaster_list = []\n",
    "\n",
    "lan_words = list(vecs.keys())\n",
    "\n",
    "with tqdm(total=len(lan_words)*len(lan_words)/2.0) as pbar:\n",
    "    while len(lan_words) > 0:\n",
    "        item = lan_words.pop()\n",
    "\n",
    "        x =  vecs[item]\n",
    "    \n",
    "        for word in lan_words:\n",
    "            if word is not item:\n",
    "                y =  vecs[word]\n",
    "                cosine_sim = dot(x, y)/(norm(x)*norm(y))\n",
    "\n",
    "                if cosine_sim > lancaster_thresh:\n",
    "\n",
    "                    lancaster_list.append((item, word))\n",
    "                    lancaster.add_edge(item, word)\n",
    "        pbar.update(len(lan_words))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39707\n"
     ]
    }
   ],
   "source": [
    "print(len(lancaster.nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(lancaster_list, open( \"lancaster_full.pickle\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Mean Degree of Connectivity _k_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_degree_connectivity(lancaster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Mean Clustering Coefficient _CC_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.average_clustering(lancaster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Assortativity Coefficient _a_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.degree_assortativity_coefficient(lancaster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Percetage of nodes in the LCC _Conn._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perc_nodes_in_lcc(lancaster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) Mean shortest path length in LCC _d_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_shortest_path_lcc(lancaster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(lancaster.nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now, we will add the above created layers to the multiplex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"free_assoc_full.pickle\", \"rb\") as input_file:\n",
    "    free_assoc = pickle.load(input_file)\n",
    "    \n",
    "with open(r\"word_emb_layer_full.pickle\", \"rb\") as input_file:\n",
    "    word_emb_list = pickle.load(input_file)    \n",
    "    \n",
    "with open(r\"visual_graph_full.pickle\", \"rb\") as input_file:\n",
    "    visual_list = pickle.load(input_file)        \n",
    "    \n",
    "with open(r\"lancaster_full.pickle\", \"rb\") as input_file:\n",
    "    lancaster_list = pickle.load(input_file)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(free_assoc))\n",
    "print(len(word_emb_list))\n",
    "print(len(visual_list))\n",
    "print(len(lancaster_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = {'free_assoc':free_assoc,\n",
    "          'word_emb_list':word_emb_list,\n",
    "          'visual_list':visual_list, \n",
    "          'lancaster_list':lancaster_list}\n",
    "\n",
    "len(layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain, combinations\n",
    "\n",
    "def powerset(iterable):\n",
    "    \"powerset([1,2,3]) --> () (1,) (2,) (3,) (1,2) (1,3) (2,3) (1,2,3)\"\n",
    "    s = list(iterable)\n",
    "    return list(chain.from_iterable(combinations(s, r) for r in range(len(s)+1)))\n",
    "\n",
    "all_subsets = powerset(layers.keys())\n",
    "all_subsets.pop(0) # the first subset is the empty set\n",
    "print(len(all_subsets))\n",
    "all_subsets[14:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sub_layers in all_subsets[14:]:\n",
    "    print(sub_layers)\n",
    "    \n",
    "    words = []\n",
    "    for k in sub_layers:\n",
    "        i = layers[k]\n",
    "        for a,b in i:\n",
    "            words.append(a)\n",
    "            words.append(b)\n",
    "\n",
    "    words = list(set(words)) \n",
    "    print(len(words))\n",
    "\n",
    "    new_3 = nx.Graph()\n",
    "#     new_3.add_nodes_from(words)\n",
    "    \n",
    "    for k in sub_layers:\n",
    "        for pair in layers[k]:\n",
    "            new_3.add_edge(pair[0], pair[1])    \n",
    "\n",
    "    print(len(new_3.nodes))\n",
    "    print('k', mean_degree_connectivity(new_3))\n",
    "    print('CC', nx.average_clustering(new_3))\n",
    "    print('a', nx.degree_assortativity_coefficient(new_3))\n",
    "    print('conn', perc_nodes_in_lcc(new_3))\n",
    "    print('d', mean_shortest_path_lcc(new_3))\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "('free_assoc',)\n",
    "13744\n",
    "k 5.968277066356229\n",
    "CC 0.18140117405816272\n",
    "a -0.1378838837754419\n",
    "conn 0.9985448195576252\n",
    "d 4.9834091852721665\n",
    "\n",
    "('word_emb_list',)\n",
    "25558\n",
    "k 1119.9501525940998\n",
    "CC 0.6476716252456551\n",
    "a 0.1769889275645062\n",
    "conn 0.8268643868847327\n",
    "d 3.069093343628048\n",
    "\n",
    "('visual_list',)\n",
    "11811\n",
    "k 2464.240284480569\n",
    "CC 0.8647897461330403\n",
    "a -0.4776667293884356\n",
    "conn 0.9993226653119973\n",
    "d 1.868065777870662\n",
    "\n",
    "('lancaster_list',)\n",
    "39662\n",
    "k 2542.666784327568\n",
    "CC 0.5281151568371529"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
