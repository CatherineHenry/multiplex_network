{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Child vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "vocab = [line.strip() for line in open('../data/vertomul.txt')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unpack Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "free_assoc = pickle.load( open( \"free_assoc.pickle\", \"rb\" ))\n",
    "co_oc = pickle.load( open( \"co_oc.pickle\", \"rb\" ))\n",
    "phon_conn = pickle.load( open( \"phon_conn.pickle\", \"rb\" ))\n",
    "feat_norms = pickle.load( open( \"feat_norms.pickle\", \"rb\" ))\n",
    "word_emb_layer = pickle.load( open( \"word_emb_layer.pickle\", \"rb\" ))\n",
    "visual_layer = pickle.load( open( \"visual_graph.pickle\", \"rb\" ))\n",
    "lancaster_layer = pickle.load( open( \"lancaster.pickle\", \"rb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lancaster_layer - it introduces new nodes \n",
    "lists = [ co_oc, phon_conn, free_assoc, feat_norms, word_emb_layer, visual_layer, lancaster_layer]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct weighted graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregate = nx.Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregate.add_nodes_from(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "529"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregate.number_of_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "529\n",
      "529\n",
      "529\n",
      "529\n",
      "529\n",
      "529\n",
      "529\n"
     ]
    }
   ],
   "source": [
    "# setting the weights. If the connection between two nodes is established across multiple layers, we up its weight\n",
    "for a_list in lists:\n",
    " \n",
    "    for pair in a_list:\n",
    "      \n",
    "        if aggregate.has_edge(pair[0], pair[1]):\n",
    "            aggregate[pair[0]][pair[1]]['weight'] += 1\n",
    "        else:\n",
    "#             print(\"adding nodes on\", pair[0], pair[1])\n",
    "            aggregate.add_edge(pair[0], pair[1], weight=1)\n",
    "    print(aggregate.number_of_nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: ISSUE HERE!! The network has more nodes than the vocab. Caused by the Lancaster layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_weights(G):\n",
    "    '''\n",
    "     This function creates a list of\n",
    "     normalized weights for each node \n",
    "     in the G graph. The sum of the \n",
    "     weights sum to 1.\n",
    "    '''\n",
    "    normalized_weights = []\n",
    "    weights = list(G.degree(weight='weight')) # strength of each node\n",
    "    overall = sum(node[1] for node in weights) # sum of all weights in graph \n",
    "    \n",
    "    for node in weights:\n",
    "        perc = node[1]/overall\n",
    "        normalized_weights.append(perc)\n",
    "    \n",
    "    return normalized_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_node_connections(G, batch):\n",
    "    '''\n",
    "     This function returns a list of\n",
    "     tuples with (node, edge) pairings\n",
    "     for each connection a node has. \n",
    "    '''\n",
    "    list_conns = []\n",
    "    for node in batch:\n",
    "        list_conns.append(G.edges(node))\n",
    "    return list_conns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    " def preferential_attachment(G, vocab, weights, batch_size):\n",
    "    '''\n",
    "     preferential attachment function call takes in a graph \n",
    "     and a list of tuples --> for each node in the batch list,\n",
    "     get all of its edges and create a list of tuples.\n",
    "    '''\n",
    "    \n",
    "    # create a random batch of nodes\n",
    "    batch = np.random.choice(vocab, batch_size,replace=False,p=weights)\n",
    "    \n",
    "    # create a list of tuples (node, edge) for each edge a node has\n",
    "    list_conns = get_node_connections(G, batch)\n",
    "    \n",
    "    node_avgs_list = []\n",
    "    for arr in list_conns:\n",
    "        # compute preferential attachment on batch nodes\n",
    "        preds = nx.preferential_attachment(aggregate, arr)\n",
    "        \n",
    "        # get the average of all the attachments for each node\n",
    "        node_avgs = np.mean([p for u,v,p in preds])\n",
    "        node_avgs_list.append(node_avgs)\n",
    "    \n",
    "    # list with averages preferential attachment scorer for each node in batch\n",
    "    zip_lists = list(zip(batch, node_avgs_list))\n",
    "\n",
    "    return zip_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_weights = normalize_weights(aggregate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('bug', 7888.0),\n",
       " ('animal', 6202.0),\n",
       " ('a', 14494.0),\n",
       " ('comb', 5284.0),\n",
       " ('box', 7605.0),\n",
       " ('little', 8605.0),\n",
       " ('before', 5403.0),\n",
       " ('downtown', 6505.0),\n",
       " ('all', 12796.0),\n",
       " ('throw', 1996.0),\n",
       " ('mailman', 9756.0),\n",
       " ('finish', 9705.0),\n",
       " ('spill', 5012.0),\n",
       " ('airplane', 12941.0),\n",
       " ('red', 2553.0),\n",
       " ('ant', 5141.0),\n",
       " ('egg', 2597.0),\n",
       " ('where', 10883.0),\n",
       " ('what', 9440.0),\n",
       " ('please', 5850.0)]"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = preferential_attachment(aggregate, vocab, normalized_weights, 20)\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation between batch and AoA dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe for batch --> (node, score)\n",
    "df = pd.DataFrame(data=res, columns=['word', 'preferential attachment score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe for aoa dataset --> (word, age_avg)\n",
    "aoa = pd.read_excel('../data/AoA_ratings.xlsx')\n",
    "aoa.drop(aoa.columns[[1, 2, 3, 5, 6]], axis = 1, inplace = True) # we are only interested in the mean column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A note on the Pearson correlation\n",
    "The Pearson correlation varies between -1 and +1 with 0 implying no correlation. Correlations of -1 or +1 imply an exact linear relationship. Positive correlations imply that as x increases, so does y. Negative correlations imply that as x increases, y decreases.\n",
    "The p-value roughly indicates the probability of an uncorrelated system producing datasets that have a Pearson correlation at least as extreme as the one computed from these datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AoA_correlation(aoa, df):\n",
    "    \n",
    "    # get list of batch words\n",
    "    res_words = [word[0] for word in res]   \n",
    "    \n",
    "    # reduce the aoa dataframe to the \n",
    "    # rows that match our batch\n",
    "    for index, row in aoa.iterrows():\n",
    "        if row['Word'] not in res_words:\n",
    "            aoa.drop(index, inplace=True)\n",
    "            \n",
    "    # rearrage the df dataframe in ascending order \n",
    "    # (the aoa dataframe is already sorted)\n",
    "    df.sort_values([\"word\"], ascending = (True), inplace=True)\n",
    "    \n",
    "    # if the two sets are not the same, it means that the aoa \n",
    "    # dataset doesn't have some words tha the vocab has\n",
    "    if len(aoa) != len(df): \n",
    "        print(\"The lists are not the same\")\n",
    "        \n",
    "        # get the data into lists\n",
    "        df_scores = df['word'].to_list()\n",
    "        aoa_scores = aoa['Word'].to_list()\n",
    "        \n",
    "        # intersection of the two sets\n",
    "        valid_words = list(set(df_scores) & set(aoa_scores)) \n",
    "\n",
    "        # remove the words that are not found \n",
    "        # in the aoa from the df\n",
    "        for index, row in df.iterrows(): \n",
    "            print(row['word'])\n",
    "            if row['word'] not in valid_words:\n",
    "                df.drop(index, inplace=True)\n",
    "        \n",
    "    # the sets are now the same and we can\n",
    "    # correlate them\n",
    "    df_scores = df['preferential attachment score'].to_list()\n",
    "    aoa_scores = aoa['Rating.Mean'].to_list()\n",
    "    correlation, p_value = pearsonr(df_scores, aoa_scores)# returns the correlation score and the \n",
    "\n",
    "    return correlation \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.08957911265388938"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = AoA_correlation(aoa, df)\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
